:warning: Порой темные электрические силы мешают GitHub корректно отображать файлы формата `ipynb`. Если такое случилось и в этот раз, то можно просмотреть код проекта в nbviewer.jupyter.org по [этой ссылке](https://nbviewer.jupyter.org/github/konstantin-samsonov/test_tasks/blob/master/Cindicator_ProductAnalyst/Cindicator_ProductAnalyst.ipynb) 

# Тестовое задание Product Analyst

## Задача
В продукте решили провести эксперимент, призванный улучшить конверсию C1 (sign-up->purchase) в мобильных приложениях Stoic на обеих платформах. Для этого в приложении изменили порядок шагов в воронке, поставив шаг воронки «платеж» раньше, чем шаг воронки «привязка кошелька». Версия появилась в сторах 19.12.2020.

Задачи:
1. Используя данные выгрузок из внутренней платежной системы (payments) и из аналитической системы (sign-ups), определите, получилось ли добиться цели эксперимента, произведя необходимые расчеты и описав методологию расчётов и выводы в документе. Для решения задачи можно использовать любой аналитический пакет (Python, R, Excel, Spreadsheets etc), приложите код/файл с расчетами вместе с документом с выводами.
2. Если возможно, определите наиболее эффективные каналы привлечения и другие важные параметры юнит-экономики продукта, которые заметите на основе данных из п.1.
3. Определите потенциальные проблемные зоны в механизмах сбора данных.
 

## Решение
### Вопрос №1 - результат эксперимента

**Выводы:**
- Эксперимент по увеличению конверсии С1 признать успешным. До внедрения новой пользовательской воронки конверсия составлял 12%. После 19%. Z-тест показал, что разница в данных не случайна и является статистически значимой с вероятностью в 95%.
- Однако, если оценивать эксперимент с точки зрения заработанных сервисом денег, то выясняется, что при сопоставимом количестве платящих пользователей больше денег приносила группа А (до введения эксперимента). 
В таком свете трудно признать эксперимент по изменению воронки 100% успешным. Если бы в предоставленных данных была информация о стоимости привлечения пользователя и LTV, то можно было бы рассчитать ROI и более взвешенно (как мне кажется) оценить успех/провал эксперимента.  

**Методология расчета:**

После предварительного знакомства с данными и анализа всех имеющихся метрик было принято решение - двигаться от задачи. Обрабатывать/проверять/чистить только те данные, которые, как мне кажется, необходимы для ответа на поставленный вопрос. Поэтому порядок действий был такой:

- Преобразовать даты в переменных `cohort`, почистить мусор и восстановить пропуски там, где это возможно сделать по данным `payment_dt`.
- Разбить пользователей на две группы A/B. A - до изменений воронки. В - после изменения воронки.
- Проверить отсутствие эффекта "подглядывания", чтобы один и тот же пользователь не попал в разные группы.
- Очистить дубликаты пользователей по email. В ходе анализа появилось предположение, что данные дубли - это рабочие аккаунты сотрудников сервиса.
- Посчитать конверсию C1 используя следующую логику:
    - на этапе воронки `sign-up` учитывать только тех пользователей, у которых есть данные в `cohort_date`
    - на этапе воронки `purchase` учитывать только тех пользователей, у которых есть данные в `payment_date`
    - рассчитать количество пользователей и проверить статистическую значимость результатов с помощью Z-теста.
- Дополнительно проверить изменения в доходе, который получил сервис в рамках эксперимента (до/после)  




### Вопрос №2 - наиболее эффективные каналы привлечения, и другие важные параметры юнит-экономики

**ТОП5 самых эффективных каналов:**
- landing_email
- blog
- landing
- QR_code
- Telegram Promo

Хуже всего отработал платный ([как я подозреваю](https://bidease.com/)) источник трафика `bidease_int`. Данный источник позволил привлечь максимум трафика (2546 пользователей), но конверсия в платящих пользователей составила всего 0.078555% (2 пользователя). 

Конечно я не исключаю возможности отложенной конверсии, когда пользователи по истечению какого-то времени переходят с demo-аккаунта на платный тариф. Но предоставленные данные не позволят посчитать LTV и оценить так ли это.

**DAU, WAU, MAU**

- DAU - 21 пользователь
- WAU - 119 пользователей
- MAU - 388 пользователей
- sticky factor WAU: 17.65%
- sticky factor MAU: 5.41%

 Думаю, что было бы полезно сравнить "привлекательность" приложения  с продуктами конкурентов (если есть такая возможность), а также с отраслевыми стандартами.
Мне кажется странным, что такая низкая "привлекательность" у приложения про деньги, которые пользователи планируют заработать или хотя бы не потерять. Возможно, что стоит поработать над увеличением данных значений, и стимулировать аудиторию возвращаться как можно чаще.

**APRU**
По хорошему ARPU надо считать за месяц. Но данных по оплатам так мало, что это все выглядит как-то грустно. Поэтому посчитаю его за весь временной период.

- ARPU - 87.02304347826087

**Marketing cost, CPA, CAC, LTV, Retention, Margin** - все эти чудесные метрики нельзя сейчас рассчитать, так как нет исходных даных. Ну или я не вижу как это сделать, но тогда это полный провал )

### Вопрос №3 - Определите потенциальные проблемные зоны в механизмах сбора данных
- непечатные символы в выгрузках это проблема. Могут вылезти в самый неподходящий момент и сломать всю автоматизацию. Хорошо бы проверить все этапы ETL и сохранять в БД только данные, без табуляций и пробелов.
- предоставленные данные содержат большое количество пропусков. Причем порой в очень странных местах. `gp:cohort_day` ,`gp:cohort_month` , `gp:cohort_year` - почему большая часть пользователей не имеет данные о дате? Это ошибка сбора или хранения? И, честно говоря, пока не очень понятно зачем дату хранить в разных метриках? Почему не хранить все в типе дата?
- `gp:cohort_year` как в автоматическую выгрузку из системы аналитики попали 2563, 2564? Ручной ввод? Ошибка? Где и почему?
- `gp:is_demo` пожалуй можно назвать одной из ключевых метрик. Важно же понимать статус пользователя, и когда он стал платящим? Но почему так много NaN? Неужели аналитика настроена так плохо, что данные не собираются?
- `gp:capmaign` и `gp:media_source` и здесь опять пропуски, пропуски, пропуски. Откуда появились все эти пользователи без источников? Кто они?
- `dma`, `device_type`, `city` пропуски в данных из-за оператора связи, или что-то сломалось на этапе сбора и хранения информации?
- Почему пользователи с одним email получают разные `amplitude_id`? Их оказалось всего 13, но ведь если это какой-то баг, то завтра таких пользователей может стать 130
- У 54% пользователей с `payment_dt` нет данных в `cohort_date`, и это странно. Получается, что эти пользователи не попали ни в какую когорту для аналитики, но они есть в платежках.
- `gp:capmaign` нужно прививать культуру нормального названия источников/кампаний )

---

Можно было еще больше покопаться в даных и поискать взаимосвязь между конверсией и типом телефона/версией операционки/версией, установленного приложения/регионом/городом. Но мне кажется, что общий уровень работы получится оценить и по уже готовому отчету )